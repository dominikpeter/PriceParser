{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import turbodbc\n",
    "import _main as pp\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pivot(df):\n",
    "    pvt = pd.DataFrame()\n",
    "    cols = ['Preis_Konkurrenz',\n",
    "            'Txt_Kurz_Konkurrenz',\n",
    "            'Txt_Lang_Konkurrenz',\n",
    "            'Joined_on',\n",
    "            'Preisdifferenz',\n",
    "            'Closest', 'Distance']\n",
    "    for i in cols:\n",
    "        pvt_ = df.pivot(index='UID', columns='Konkurrenz', values=i)\n",
    "        pvt_.columns = [i+'_'+j for j in pvt_.columns]\n",
    "        pvt = pd.concat([pvt, pvt_], axis=1)\n",
    "    pvt = df.merge(\n",
    "        pvt, left_on='UID',\n",
    "        right_index=True)\n",
    "    pvt.drop(cols, axis=1, inplace=True)\n",
    "    pvt.drop('Konkurrenz', axis=1, inplace=True)\n",
    "    pvt.drop_duplicates(inplace=True)\n",
    "    return pvt.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies(df):\n",
    "    companies = [i[17:] for i in df.columns if i.startswith(\n",
    "        \"Preis_\") and not i.endswith(\"Log\")]\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    companies = get_companies(df)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.replace('\\n', '', inplace=True)\n",
    "    df.replace('\\r', '', inplace=True)\n",
    "    for j, i in enumerate(companies):\n",
    "        print(\"{} Company in data: {}\".format(j, i))\n",
    "    df['Discount_perc'] = (df['GrossSales_LTM'] - df['Sales_LTM']) / df['GrossSales_LTM']\n",
    "    df['Margin_perc'] = df['Margin_LTM'] / df['Sales_LTM']\n",
    "\n",
    "    for i in ['GrossSales_LTM', 'Sales_LTM',\n",
    "              'Margin_LTM', 'Quantity_LTM',\n",
    "              'ObjectRate', 'CountOfOrders', 'Preis',\n",
    "              'CountOfCustomers', 'Discount_perc', 'Margin_perc']:\n",
    "        df[i] = df[i].astype(np.float)\n",
    "        df[i+'_Log'] = df[i].apply(lambda x: np.log(x+1))\n",
    "    \n",
    "    df['GrossSales_Caluclated'] = df['Preis'] * df['Quantity_LTM']\n",
    "    \n",
    "    for i in companies:\n",
    "        df['Preis_Konkurrenz_'+i] = df['Preis_Konkurrenz_'+i].astype(np.float)\n",
    "        df['Preis_Konkurrenz_'+i+'_Log'] = df['Preis_Konkurrenz_'+i].apply(lambda x: np.log(x+1))\n",
    "        df['Outlier_'+i] = np.nan\n",
    "        df['GrossSales_Caluclated_'+i] = df['Preis_Konkurrenz_'+i] * df['Quantity_LTM']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df, X=None, tag='', clusters=5, scaler_obj=StandardScaler):\n",
    "    if tag in df.columns:\n",
    "        df[tag] = np.nan\n",
    "    if not X:\n",
    "        X = df\n",
    "    else:\n",
    "        X = df[X]\n",
    "    norm = scaler_obj()\n",
    "    normalized = norm.fit_transform(X)\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=clusters, random_state=23).fit(normalized)\n",
    "    df[tag] = kmeans.labels_\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(df, threshold=1.5):\n",
    "    companies = get_companies(df)\n",
    "    for i in companies:\n",
    "        df_temp = df[['Preis', 'Preis_Konkurrenz_'+i]].replace('',np.nan).dropna(how='any').copy()\n",
    "        df_temp['Preis'] = df_temp['Preis'].astype(np.float)\n",
    "        df_temp['Preis_Konkurrenz_'+i] = df_temp['Preis_Konkurrenz_'+i].astype(np.float)\n",
    "        df_temp['Diff'] = df_temp['Preis'] - df_temp['Preis_Konkurrenz_'+i]\n",
    "        df['Outlier_'+i] = False\n",
    "        df_temp['Outlier_'+i] = (np.abs(\n",
    "                df_temp['Diff']) / df_temp['Preis']) > threshold * (\n",
    "                np.std(df_temp['Diff']) / df_temp['Preis'])\n",
    "        df.update(df_temp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(df, plot=True):\n",
    "    mapper1 = {0: \"Low Margin, Low Sales\",\n",
    "               1: \"Low Margin, High Sales\",\n",
    "               2: \"High Margin, Low Sales\",\n",
    "               3: \"High Margin, High Sales\"}\n",
    "\n",
    "    mapper2 = {0: \"Low Quantity, Medium Sales\",\n",
    "               1: \"Medium Quantity, High Sales\",\n",
    "               2: \"Medium Quantity, Medium Sales\",\n",
    "               3: \"High Quantity, High Sales\",\n",
    "               4: \"Low Quantity, Low Sales\"}\n",
    "\n",
    "    mapper3 = {0: \"Low ObjectRate, Medium Sales\",\n",
    "               1: \"Low Sales, High ObjectRate\",\n",
    "               2: \"High Sales\",\n",
    "               3: \"Low Sales, Low ObjectRate\"}\n",
    "    \n",
    "    for i in [['Margin_perc', 'Sales_LTM_Log', StandardScaler, 4, mapper1],\n",
    "              ['Quantity_LTM_Log', 'Sales_LTM_Log', StandardScaler, 5, mapper2],\n",
    "              ['ObjectRate', 'Sales_LTM_Log', StandardScaler, 4, mapper3]]:\n",
    "\n",
    "        tag = 'Cluster_'+'_'.join(i[:2])\n",
    "\n",
    "        dfs = df.query(\"Margin_perc > 0.0001 and Sales_LTM > 100 and Margin_perc < 0.8\").copy()\n",
    "        dfs = dfs.pipe(cluster, X=[i[0], i[1]], tag=tag, clusters=i[3], scaler_obj=i[2])\n",
    "        dfs[tag] = dfs[tag].map(i[4])\n",
    "        \n",
    "        if plot:\n",
    "            sns.lmplot(i[0], i[1],\n",
    "                       data=dfs, hue=tag,\n",
    "                       fit_reg=False, size=7,\n",
    "                       aspect=1.6,\n",
    "                       palette=sns.color_palette('colorblind'))\n",
    "\n",
    "            plt.savefig(os.path.join(pp.Path, \"Plots\",\"PDF\", tag+\".pdf\"))\n",
    "            plt.savefig(os.path.join(pp.Path, \"Plots\",\"PNG\", tag+\".png\"))\n",
    "\n",
    "        df[tag] = np.nan\n",
    "        df.update(dfs[tag])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outlier(df):\n",
    "    for i in get_companies(df):\n",
    "        dfplot = df[(df['Joined_on_'+i] != 'Text_Similarity') & (pd.notnull(\n",
    "            df['Preis_Konkurrenz_'+i]))]\n",
    "        f, ax = plt.subplots(figsize=(20, 20))\n",
    "        p1 = sns.regplot('Preis_Konkurrenz_'+i, 'Preis', data=dfplot, fit_reg=False)    \n",
    "        for line in range(0,dfplot.shape[0]):\n",
    "            if dfplot.Outlier_Sanitas.iloc[line]:\n",
    "                p1.text(dfplot.Preis_Konkurrenz_Sanitas.iloc[line]+0.5,\n",
    "                        dfplot.Preis.iloc[line], dfplot.Art_Txt_Kurz.iloc[line],\n",
    "                        horizontalalignment='left', size='medium', color='black')\n",
    "        plt.savefig(os.path.join(pp.Path, \"Plots\",\"PDF\", \"Outlier_{}.pdf\".format(i)))\n",
    "        plt.savefig(os.path.join(pp.Path, \"Plots\",\"PGN\", \"Outlier_{}.pgn\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT UniqueId\n",
    "      ,GrossSales_LTM = sum(GrossSales)\n",
    "      ,Sales_LTM = sum(Sales)\n",
    "      ,Margin_LTM = sum(Margin)\n",
    "      ,Quantity_LTM = sum(Quantity)\n",
    "      ,ObjectRate = max(ObjectRate)\n",
    "      ,CountOfOrders = sum(CountOfOrders)\n",
    "      ,CountOfCustomers = sum(CountOfCustomers)\n",
    "    FROM (\n",
    "    SELECT UniqueId = idItemOld\n",
    "      ,GrossSales = sum(GrossSales)\n",
    "      ,Sales = sum(Sales)\n",
    "      ,Margin = sum(Margin)\n",
    "      ,Quantity = sum(Quantity)\n",
    "      ,ObjectRate = avg(case when PricingLong IN ('Offerte', 'Baustelle', 'Aktionspreise') then 1.0 else 0.0 end)\n",
    "      ,CountOfOrders = count(distinct OrderNo)\n",
    "      ,CountOfCustomers = count(distinct idCustomer)\n",
    "    FROM CRHBUSADWH01.InfoPool.FACT.V_Sales s\n",
    "      inner join CRHBUSADWH01.infopool.dim.v_item i on i.iditem = s.iditem and i.idbusinesssection = s.idbusinesssection\n",
    "      inner join [CRHBUSADWH01].[InfoPool].[DIM].[V_Pricing] p on p.idpricing = s.idpricing\n",
    "    where itemgroupgrouphierarchyname_l1 = '05-SanitÃ¤r'\n",
    "    and Date > dateadd(month, -12, getdate())\n",
    "    and Sales > 0\n",
    "    group by idItemOld\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT UniqueId = substring(i.iditemorigin, 2, 500)\n",
    "      ,GrossSales = sum(GrossSales)\n",
    "      ,Sales = sum(Sales)\n",
    "      ,Margin = sum(Margin)\n",
    "      ,Quantity = sum(Quantity)\n",
    "      ,ObjectRate = 0\n",
    "      ,CountOfOrders = count(distinct OrderNo)\n",
    "      ,CountOfCustomers = count(distinct idCustomer)\n",
    "    FROM InfoPool_MOV.FACT.Sales s\n",
    "      inner join InfoPool_MOV.DIM.v_item i on i.iditem = s.iditem\n",
    "    where itemgroupgrouphierarchyname_l1 = '05-SanitÃ¤r'\n",
    "    and Date > dateadd(month, -12, getdate())\n",
    "    and Sales > 0\n",
    "    group by substring(i.iditemorigin, 2, 500)\n",
    "    ) x\n",
    "    GROUP BY UniqueId\n",
    "    HAVING sum(Sales)>0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pp.create_connection_string_turbo(\"CRHBUSADWH02\", 'AnalystCM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pp.sql_to_pandas(con, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in os.listdir(os.path.join(pp.Path, \"Matched\")) if i.endswith(\".tsv\")]\n",
    "files.sort(reverse=True)\n",
    "file = files[0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(os.path.join(pp.Path, \"Matched\", file), sep=\"\\t\", dtype=str)\n",
    "        .pipe(to_pivot)\n",
    "        .merge(meta, how='left', left_on='UID', right_on='UniqueId')\n",
    "        .pipe(prep_df)\n",
    "        .drop_duplicates(inplace=False)\n",
    "        .pipe(outlier_detection, threshold=5)\n",
    "        .pipe(get_cluster, plot=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['Art_Txt_Kurz'].str.contains(\n",
    "    'procasa', case=False)].to_csv(\n",
    "    os.path.join(pp.Path, \"Analyse\", \"Output_Analysis.tsv\"),\n",
    "    sep=\"\\t\", encoding='utf-8', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
