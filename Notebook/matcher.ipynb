{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import helper as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame({\"A\": [1,2,3,4,5,'',''], \"B\": [1,2,np.nan,4,np.nan,np.nan,np.nan]})\n",
    "tdf2 = pd.DataFrame({\"A\": [1,2,'',4,5,6,7], \"B\": [1234234,2234234324,3223423,4232323,523323,1212,np.nan]})\n",
    "tdf3 = pd.DataFrame({\"A\": [1,2,3,4,'',6,7], \"B\": [1,2,3,4,5,6,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_id(head, tail):\n",
    "    r = ''\n",
    "    try:\n",
    "        if head:\n",
    "            r = str(head) + ''.join(tail)\n",
    "    except TypeError:\n",
    "        r = head\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_string_join(x):\n",
    "    try:\n",
    "        joined = ''.join(x)\n",
    "    except TypeError:\n",
    "        joined = x\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_list_or_tuple(object):\n",
    "    return isinstance(object, (list, tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_string(object):\n",
    "    return isinstance(object, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_or_empty(x):\n",
    "    def bitwise_non_or_empty(x):\n",
    "        boo = False\n",
    "        if pd.isna(x):\n",
    "            boo = True\n",
    "        if x == None:\n",
    "            boo = True\n",
    "        if x == '':\n",
    "            boo = True\n",
    "        return boo\n",
    "    boo = x.apply(\n",
    "        lambda x: bitwise_non_or_empty(x))\n",
    "    return boo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_threshold(x, y, threshold):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    x[abs(x - y) > threshold] = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_update(left, right, left_on, right_on,\n",
    "                    left_update, right_update, joined_on=\"\"):\n",
    "    \n",
    "    assert(check_if_list_or_tuple(\n",
    "        left_update) == check_if_list_or_tuple(\n",
    "        right_update))\n",
    "    \n",
    "    if right_on == 'Index':\n",
    "        right['Index'] = right.index\n",
    "        \n",
    "    if left_on == 'Index':\n",
    "        left['Index'] = left.index\n",
    "\n",
    "    if check_if_string(left_update):\n",
    "        left_update = [left_update]\n",
    "        \n",
    "    if check_if_string(right_update):\n",
    "        right_update = [right_update]\n",
    "        \n",
    "    left = left.copy()\n",
    "    righ = right.copy()\n",
    "            \n",
    "    if 'Joined_on' not in left.columns:\n",
    "        left['Joined_on'] = np.nan\n",
    "        \n",
    "    left[left_on] = left[left_on].replace('', np.nan)\n",
    "    \n",
    "    left_to_match = left[non_or_empty(left[left_update[0]])]\n",
    "    left_matched = left[~non_or_empty(left[left_update[0]])]\n",
    "    \n",
    "    mb = left_to_match.shape[0]\n",
    "    \n",
    "    cols = [right_on]\n",
    "\n",
    "    for i in right_update:\n",
    "        cols.append(i)\n",
    "\n",
    "    right = right[cols].copy()\n",
    "    right[right_on] = right[right_on].replace('', np.nan)\n",
    "\n",
    "    df_join = left_to_match.pipe(save_join, right=right, left_on=left_on,\n",
    "                        right_on=right_on,\n",
    "                        suffixes=['', '___y'])\n",
    "\n",
    "    right_update = [i + '___y' for i in right_update]\n",
    "    \n",
    "    check = (non_or_empty(\n",
    "        df_join[left_update[0]])) & (~non_or_empty(\n",
    "            df_join[right_update[0]]))\n",
    "\n",
    "    df_join.loc[check, 'Joined_on'] = joined_on\n",
    "    \n",
    "    for i, j in zip(left_update, right_update):\n",
    "        df_join.loc[check, i] = df_join[j]\n",
    "    \n",
    "    df_join = df_join[[i for i in df_join.columns if not i.endswith('___y')]]\n",
    "    \n",
    "    ma = df_join[~non_or_empty(df_join[left_update[0]])].shape[0]\n",
    "    d = mb - ma\n",
    "    mb += 1.0e-10\n",
    "    print('Matched {} articles from {} ({} %)'.format(d, round(mb,0),\n",
    "                                                      round(d/mb*100, 2)))\n",
    "    \n",
    "    left = pd.concat([left_matched, df_join], axis=0).reset_index(drop=True)\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_join(left, right, left_on, right_on, *args, **kwargs): \n",
    "\n",
    "    if right_on == 'Index':\n",
    "        right['Index'] = right.index\n",
    "        \n",
    "    if left_on == 'Index':\n",
    "        left['Index'] = left.index\n",
    "\n",
    "    noe = non_or_empty(right[right_on])\n",
    "    \n",
    "    df_join = left.merge(right[~noe], how=\"left\",\n",
    "                         left_on=left_on, right_on=right_on,\n",
    "                         *args, **kwargs)\n",
    "    return df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataframe(df):\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    for i in ['FarbId', 'AusführungsId']:\n",
    "        df.loc[non_or_empty(df[i]), i] = '' \n",
    "    \n",
    "    df['Farbe'] = df['AF_Txt'].fillna('')\n",
    "    df['Ausführung'] = df['AFZ_Txt'].fillna('')\n",
    "    df['FarbId'] = df['FarbId'].replace('', '000')\n",
    "    df['Preis'] = df['Preis_Pos'].astype(float)\n",
    "    df['Art_Nr_Hersteller'].astype(str, inplace=True)\n",
    "    df['Art_Nr_Hersteller'].fillna('', inplace=True)\n",
    "        \n",
    "    df['UID'] = df[['ArtikelId',\n",
    "                   'FarbId',\n",
    "                   'AusführungsId']].apply(\n",
    "        lambda x: create_unique_id(x), axis=1)\n",
    "    \n",
    "    df['Art_Nr_Hersteller_UID'] = df[['Art_Nr_Hersteller',\n",
    "                                      'FarbId',\n",
    "                                      'AusführungsId']].apply(\n",
    "        lambda x: create_unique_id(x), axis=1)\n",
    "    \n",
    "    if 'Konkurrenzummer' in df.columns:\n",
    "        df['Konkurrenznummer'].astype(str, inplace=True)\n",
    "        df['Konkurrenznummer'].fillna('', inplace=True)\n",
    "        df['Konkurrenznummer'] = df[['Konkurrenznummer',\n",
    "                                      'FarbId',\n",
    "                                      'AusführungsId']].apply(\n",
    "        lambda x: create_unique_id(x), axis=1)\n",
    "    \n",
    "    df['Art_Nr_Hersteller'].replace('', np.nan, inplace=True)\n",
    "    df['Art_Nr_Hersteller_UID'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    df.loc[df['Art_Nr_Hersteller'].str.len() < 5, 'Art_Nr_Hersteller'] = np.nan\n",
    "    df.loc[df['Art_Nr_Hersteller_UID'].str.len() < 5, 'Art_Nr_Hersteller_UID'] = np.nan\n",
    "    \n",
    "    df['EAN'] = df['Preis_EAN'].fillna(df['Art_Nr_EAN'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dotdat(df, dotdat, right_on, left_on):\n",
    "    df = df.pipe(save_join, right = dotdat,\n",
    "                 right_on=right_on, left_on=left_on,\n",
    "                 suffixes=['', '___y'])\n",
    "    \n",
    "    def clean_number(x):\n",
    "        try:\n",
    "            c = re.sub(\"\\s|\\D\", \"\", x)\n",
    "        except TypeError:\n",
    "            c = ''\n",
    "        return c[:6]\n",
    "    \n",
    "    dotdat['Konkurrenznummer'] = dotdat['Konkurrenznummer'].apply(\n",
    "        lambda x: clean_number(x))\n",
    "    \n",
    "    try:\n",
    "        df['Konkurrenznummer'] =  df['Konkurrenznummer___y']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    df = df[[i for i in df.columns if not i.endswith('___y')]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(left, right, chunksize=5000,\n",
    "                threshold=0.5, n_jobs=1, method='cosine',\n",
    "                columns = ['Art_Txt_Lang', 'Art_Txt_Kurz',\n",
    "                          'Farbe', 'Ausführung']):\n",
    "   \n",
    "    n_jobs = max(1, n_jobs)\n",
    "    vec = CountVectorizer()\n",
    "    \n",
    "    ix = left.index\n",
    "    \n",
    "    X = vec.fit_transform(left[columns].fillna('').astype(\n",
    "        str).apply(lambda x: ' '.join(x), axis=1))\n",
    "    Y = vec.transform(right[columns].fillna('').astype(\n",
    "        str).apply(lambda x: ' '.join(x), axis=1))\n",
    "    \n",
    "    arr = np.empty((X.shape[0], 2))\n",
    "    print('Remaining Columns to match = {} ({} Batches)\\n'.format(\n",
    "        X.shape[0], math.ceil(X.shape[0] / chunksize)))\n",
    "    \n",
    "    for i, a in tqdm.tqdm(zip(pp.batch(X, chunksize),\n",
    "                              pp.batch(arr, chunksize))):\n",
    "        distance = pairwise_distances(i, Y, metric='cosine', n_jobs=n_jobs)\n",
    "        distance_min = distance.min(axis=1)\n",
    "        distance_argmin = distance.argmin(axis=1)\n",
    "        a[:, 0] = distance_min\n",
    "        a[:, 1] = distance_argmin\n",
    "        \n",
    "    distance_df = pd.DataFrame(\n",
    "        arr,\n",
    "        columns=['Distance', 'Closest'],\n",
    "        index=ix)\n",
    "    \n",
    "    distance_df['Closest'].astype(np.int, inplace=True)\n",
    "    distance_df = distance_df[distance_df['Distance'] < threshold]\n",
    "    return distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_prices(left, right, UID=False):\n",
    "    for i in [('UID', 'UID'),\n",
    "              ('EAN', 'EAN'),\n",
    "              ('Art_Nr_Hersteller_UID', 'Art_Nr_Hersteller_UID'),\n",
    "              ('Art_Nr_Hersteller', 'Art_Nr_Hersteller'),\n",
    "              ('Konkurrenznummer', 'UID')]:\n",
    "        if i[0] == 'UID' and not UID:\n",
    "            print(\"Not joining on UID\")\n",
    "            continue\n",
    "        else:\n",
    "            print('Joining on {} and {}'.format(i[0], i[1]))\n",
    "            left = left.pipe(join_and_update, right,\n",
    "                             left_on=i[0], right_on=i[1],\n",
    "                             left_update=['Preis_Konkurrenz','Txt_Kurz_Konkurrenz','Txt_Lang_Konkurrenz'],\n",
    "                             right_update=['Preis','Art_Txt_Kurz', 'Art_Txt_Lang'],\n",
    "                             joined_on=i[0])\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_on_distance(left, right, distance):\n",
    "    left = left.join(distance, rsuffix='___y')\n",
    "    left = left.pipe(join_and_update, right,\n",
    "                     left_on=\"Closest\",\n",
    "                     right_on='Index',\n",
    "                     left_update=['Preis_Konkurrenz','Txt_Kurz_Konkurrenz','Txt_Lang_Konkurrenz'],\n",
    "                     right_update=['Preis','Art_Txt_Kurz', 'Art_Txt_Lang'],\n",
    "                     joined_on='Text_Similarity')\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "richner = pp.csv_to_pandas(os.path.join(\"Output\", \"Richner-6150.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "richner['Preis_Konkurrenz'] = np.nan\n",
    "richner['Konkurrenz'] = 'Sanitas'\n",
    "dotdat = pp.csv_to_pandas(os.path.join(\"Files\", \"Dotdat\", \"2018-01-19_SGVSB_Dotdat_File.csv\"))\n",
    "richner = richner.pipe(join_dotdat, dotdat, left_on=\"ArtikelId\", right_on=\"Artikelnummer\")\n",
    "\n",
    "richner = richner.pipe(prep_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_dict(companies):\n",
    "    files = os.listdir(os.path.join('Output'))\n",
    "    if check_if_string(companies):\n",
    "        companies = [companies]\n",
    "    compiler = re.compile(\n",
    "        r'.*(' + '|'.join(companies).lower() + ')(?!Badmoebel).+')\n",
    "    files_to_match = [f for f in files if compiler.match(f.lower())]\n",
    "\n",
    "    files_to_match = {os.path.split(\n",
    "        i)[-1].split('-')[0]: j for i, j in zip(\n",
    "        files_to_match, files_to_match)}\n",
    "    return files_to_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_match = get_files_dict(['Sabag', 'TeamSaniDusch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sabag': 'Sabag-6160.csv', 'TeamSaniDusch': 'TeamSaniDusch-6180.csv'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_distance(df):\n",
    "    if \"Preisdifferenz\" not in df.columns:\n",
    "        df['Preisdifferenz'] = np.nan\n",
    "    df['Preisdifferenz'] = df['Preis'] - df['Preis_Konkurrenz']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(df):\n",
    "    assert(\"Preisdifferenz\" in df.columns)\n",
    "    rnk = df.sort_values(\n",
    "        ['UID', 'Preisdifferenz']).groupby(\n",
    "        'UID')['Preisdifferenz'].rank(\n",
    "        method='first')\n",
    "    \n",
    "    df['Rank'] = rnk\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_with_threshold(df, to_delete, replace=np.nan, threshold=0.5):\n",
    "    assert(\"Preisdifferenz\" in df.columns)\n",
    "    assert(\"Preis\" in df.columns)\n",
    "    check = abs(df['Preisdifferenz'] / df['Preis']) > threshold\n",
    "    if check_if_list_or_tuple(to_delete):\n",
    "        for i in to_delte:\n",
    "            df.loc[check, i] = replace\n",
    "    else:\n",
    "        df.loc[check, to_delete] = replace\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_by_rank(df):\n",
    "    df = df[df['Rank'] == 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_companies(df, dictionary, concat_df=pd.DataFrame(), UID=False):\n",
    "    for i in dictionary:\n",
    "        df_ = df.copy()\n",
    "        print('Preparing {}'.format(i))\n",
    "        compare_df = pp.csv_to_pandas(os.path.join(\"Output\", dictionary[i]))\n",
    "        df_['Preis_Konkurrenz'] = np.nan\n",
    "        df_['Txt_Kurz_Konkurrenz'] = np.nan\n",
    "        df_['Txt_Lang_Konkurrenz'] = np.nan\n",
    "        df_['Konkurrenz'] = i\n",
    "        compare_df = compare_df.pipe(prep_dataframe)    \n",
    "        df_ = df_.pipe(join_prices, right=compare_df, UID=UID)\n",
    "        distance = df_[pd.isna(df_['Preis_Konkurrenz'])].pipe(get_closest,\n",
    "                                                            compare_df, threshold=0.3)      \n",
    "        df_ = (df_.pipe(join_on_distance, compare_df, distance)\n",
    "                  .pipe(get_price_distance)\n",
    "                  .pipe(delete_with_threshold, 'Preis_Konkurrenz')\n",
    "                  .pipe(get_rank)\n",
    "                  .pipe(delete_by_rank))        \n",
    "        concat_df = pd.concat([concat_df, df_], axis=0)\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pivot(df):\n",
    "    pvt = pd.DataFrame()\n",
    "    cols = ['Preis_Konkurrenz',\n",
    "            'Txt_Kurz_Konkurrenz',\n",
    "            'Txt_Lang_Konkurrenz']\n",
    "    for i in cols:\n",
    "        pvt_ = final.pivot(index='UID', columns='Konkurrenz', values=i)\n",
    "        pvt = pd.concat([pvt, pvt_], axis=1)\n",
    "    pvt = final.merge(\n",
    "        pvt, left_on='UID',\n",
    "        right_index=True)\n",
    "    pvt.drop(cols, axis=1, inplace=True)\n",
    "    pvt.drop('Konkurrenz', axis=1, inplace=True)\n",
    "    pvt.drop_duplicates(inplace=True)\n",
    "    return pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Sabag\n",
      "Joining on UID and UID\n",
      "Matched 8984 articles from 159236.0000000001 (5.64 %)\n",
      "Joining on EAN and EAN\n",
      "Matched 8973 articles from 8984.0000000001 (99.88 %)\n",
      "Joining on Art_Nr_Hersteller_UID and Art_Nr_Hersteller_UID\n",
      "Matched 8939 articles from 8973.0000000001 (99.62 %)\n",
      "Joining on Art_Nr_Hersteller and Art_Nr_Hersteller\n",
      "Matched 8936 articles from 8939.0000000001 (99.97 %)\n",
      "Joining on Konkurrenznummer and UID\n",
      "Matched 8936 articles from 8936.0000000001 (100.0 %)\n",
      "Remaining Columns to match = 8936 (2 Batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:57, 30.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 4927 articles from 8936.0000000001 (55.14 %)\n",
      "Preparing Saneo\n",
      "Joining on UID and UID\n",
      "Matched 11504 articles from 159236.0000000001 (7.22 %)\n",
      "Joining on EAN and EAN\n",
      "Matched 11493 articles from 11504.0000000001 (99.9 %)\n",
      "Joining on Art_Nr_Hersteller_UID and Art_Nr_Hersteller_UID\n",
      "Matched 11465 articles from 11493.0000000001 (99.76 %)\n",
      "Joining on Art_Nr_Hersteller and Art_Nr_Hersteller\n",
      "Matched 11462 articles from 11465.0000000001 (99.97 %)\n",
      "Joining on Konkurrenznummer and UID\n",
      "Matched 11462 articles from 11462.0000000001 (100.0 %)\n",
      "Remaining Columns to match = 11462 (3 Batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:29, 30.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 6921 articles from 11462.0000000001 (60.38 %)\n",
      "Preparing TeamHug\n",
      "Joining on UID and UID\n",
      "Matched 10691 articles from 159236.0000000001 (6.71 %)\n",
      "Joining on EAN and EAN\n",
      "Matched 10680 articles from 10691.0000000001 (99.9 %)\n",
      "Joining on Art_Nr_Hersteller_UID and Art_Nr_Hersteller_UID\n",
      "Matched 10641 articles from 10680.0000000001 (99.63 %)\n",
      "Joining on Art_Nr_Hersteller and Art_Nr_Hersteller\n",
      "Matched 10646 articles from 10649.0000000001 (99.97 %)\n",
      "Joining on Konkurrenznummer and UID\n",
      "Matched 10646 articles from 10646.0000000001 (100.0 %)\n",
      "Remaining Columns to match = 10646 (3 Batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:12, 25.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 5433 articles from 10646.0000000001 (51.03 %)\n",
      "Preparing TeamSaniDusch\n",
      "Joining on UID and UID\n",
      "Matched 17812 articles from 159236.0000000001 (11.19 %)\n",
      "Joining on EAN and EAN\n",
      "Matched 17801 articles from 17812.0000000001 (99.94 %)\n",
      "Joining on Art_Nr_Hersteller_UID and Art_Nr_Hersteller_UID\n",
      "Matched 17757 articles from 17801.0000000001 (99.75 %)\n",
      "Joining on Art_Nr_Hersteller and Art_Nr_Hersteller\n",
      "Matched 17762 articles from 17765.0000000001 (99.98 %)\n",
      "Joining on Konkurrenznummer and UID\n",
      "Matched 17762 articles from 17762.0000000001 (100.0 %)\n",
      "Remaining Columns to match = 17762 (4 Batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:00, 28.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 10465 articles from 17762.0000000001 (58.92 %)\n",
      "Preparing Sanitas\n",
      "Not joining on UID\n",
      "Joining on EAN and EAN\n",
      "Matched 149595 articles from 159236.0000000001 (93.95 %)\n",
      "Joining on Art_Nr_Hersteller_UID and Art_Nr_Hersteller_UID\n",
      "Matched 148963 articles from 150560.0000000001 (98.94 %)\n",
      "Joining on Art_Nr_Hersteller and Art_Nr_Hersteller\n",
      "Matched 148862 articles from 149070.0000000001 (99.86 %)\n",
      "Joining on Konkurrenznummer and UID\n",
      "Matched 148868 articles from 148869.0000000001 (100.0 %)\n",
      "Remaining Columns to match = 148868 (30 Batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [04:54,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 98648 articles from 148868.0000000001 (66.27 %)\n"
     ]
    }
   ],
   "source": [
    "companies = get_files_dict(['Sabag','Saneo',\n",
    "                            'SaniDusch','TeamHug'])\n",
    "final = pd.concat([richner.pipe(loop_companies,\n",
    "                        companies,\n",
    "                        UID=True),\n",
    "                   richner.pipe(loop_companies,\n",
    "                        get_files_dict('Sanitas'),\n",
    "                        UID=False)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sanitas': 'Sanitas-6130.csv'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files_dict('Sanitas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "Article Matching for Price Comparison\n",
      "    \n",
      "© Dominik Peter\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"{}{}{}Article Matching for Price Comparison\n",
    "    \\n\\u00a9 Dominik Peter{}{}{}\"\"\".format(\n",
    "        \"\\n\"*2, \"#\"*80, \"\\n\"*2, \"\\n\"*2, \"#\"*80, \"\\n\"*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[['ArtikelId', 'FarbId', 'AusführungsId', 'UID',\n",
    "               'Art_Txt_Kurz', 'Art_Txt_Lang', 'Ausführung', 'Farbe', 'EAN',\n",
    "               'Konkurrenz', 'Konkurrenznummer', 'Warengruppe', 'Preis', 'Preis_Konkurrenz',\n",
    "               'Txt_Kurz_Konkurrenz', 'Txt_Lang_Konkurrenz', 'Joined_on',\n",
    "               'Preisdifferenz', 'Art_Nr_Hersteller_Firma',\n",
    "               'Category_Level_1', 'Category_Level_2', 'Category_Level_3',\n",
    "               'Category_Level_4', 'Closest', 'Distance']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(\"Matched\", dt.strftime(\"%Y-%m-%d\")+\"_Output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(p, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvt = final.pipe(to_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtikelId</th>\n",
       "      <th>FarbId</th>\n",
       "      <th>AusführungsId</th>\n",
       "      <th>UID</th>\n",
       "      <th>Art_Txt_Kurz</th>\n",
       "      <th>Art_Txt_Lang</th>\n",
       "      <th>Ausführung</th>\n",
       "      <th>Farbe</th>\n",
       "      <th>EAN</th>\n",
       "      <th>Konkurrenz</th>\n",
       "      <th>...</th>\n",
       "      <th>Txt_Lang_Konkurrenz</th>\n",
       "      <th>Joined_on</th>\n",
       "      <th>Preisdifferenz</th>\n",
       "      <th>Art_Nr_Hersteller_Firma</th>\n",
       "      <th>Category_Level_1</th>\n",
       "      <th>Category_Level_2</th>\n",
       "      <th>Category_Level_3</th>\n",
       "      <th>Category_Level_4</th>\n",
       "      <th>Closest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014671</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "      <td>014671000</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf flach 146 771</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf flach 146 771</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sabag</td>\n",
       "      <td>...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf flach 146 771</td>\n",
       "      <td>UID</td>\n",
       "      <td>-2.5</td>\n",
       "      <td></td>\n",
       "      <td>Ersatzteile</td>\n",
       "      <td>zu Duschenelemente</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014672</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "      <td>014672000</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf Norm 146 772</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf Norm 146 772</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sabag</td>\n",
       "      <td>...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf Norm 146 772</td>\n",
       "      <td>UID</td>\n",
       "      <td>-2.5</td>\n",
       "      <td></td>\n",
       "      <td>Ersatzteile</td>\n",
       "      <td>zu Duschenelemente</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>014673</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "      <td>014673000</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf max und senk...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf max und senk...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sabag</td>\n",
       "      <td>...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf max und senk...</td>\n",
       "      <td>UID</td>\n",
       "      <td>-2.5</td>\n",
       "      <td></td>\n",
       "      <td>Ersatzteile</td>\n",
       "      <td>zu Duschenelemente</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>014674</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "      <td>014674000</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf superflach 1...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf superflach 1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sabag</td>\n",
       "      <td>...</td>\n",
       "      <td>Tauchrohr TECEdrainline zu Ablauf superflach 1...</td>\n",
       "      <td>UID</td>\n",
       "      <td>-2.5</td>\n",
       "      <td></td>\n",
       "      <td>Ersatzteile</td>\n",
       "      <td>zu Duschenelemente</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014675</td>\n",
       "      <td>000</td>\n",
       "      <td></td>\n",
       "      <td>014675000</td>\n",
       "      <td>Membran-Geruchsverschluss für Ablauf TECEdrain...</td>\n",
       "      <td>Membran-Geruchsverschluss für Ablauf TECEdrain...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sabag</td>\n",
       "      <td>...</td>\n",
       "      <td>Membran-Geruchsverschluss für Ablauf TECEdrain...</td>\n",
       "      <td>UID</td>\n",
       "      <td>-3.5</td>\n",
       "      <td></td>\n",
       "      <td>Ersatzteile</td>\n",
       "      <td>zu Duschenelemente</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td>TECEdrainline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ArtikelId FarbId AusführungsId        UID  \\\n",
       "0    014671    000                014671000   \n",
       "1    014672    000                014672000   \n",
       "2    014673    000                014673000   \n",
       "3    014674    000                014674000   \n",
       "4    014675    000                014675000   \n",
       "\n",
       "                                        Art_Txt_Kurz  \\\n",
       "0    Tauchrohr TECEdrainline zu Ablauf flach 146 771   \n",
       "1     Tauchrohr TECEdrainline zu Ablauf Norm 146 772   \n",
       "2  Tauchrohr TECEdrainline zu Ablauf max und senk...   \n",
       "3  Tauchrohr TECEdrainline zu Ablauf superflach 1...   \n",
       "4  Membran-Geruchsverschluss für Ablauf TECEdrain...   \n",
       "\n",
       "                                        Art_Txt_Lang Ausführung Farbe EAN  \\\n",
       "0    Tauchrohr TECEdrainline zu Ablauf flach 146 771                        \n",
       "1     Tauchrohr TECEdrainline zu Ablauf Norm 146 772                        \n",
       "2  Tauchrohr TECEdrainline zu Ablauf max und senk...                        \n",
       "3  Tauchrohr TECEdrainline zu Ablauf superflach 1...                        \n",
       "4  Membran-Geruchsverschluss für Ablauf TECEdrain...                        \n",
       "\n",
       "  Konkurrenz   ...                                   Txt_Lang_Konkurrenz  \\\n",
       "0      Sabag   ...       Tauchrohr TECEdrainline zu Ablauf flach 146 771   \n",
       "1      Sabag   ...        Tauchrohr TECEdrainline zu Ablauf Norm 146 772   \n",
       "2      Sabag   ...     Tauchrohr TECEdrainline zu Ablauf max und senk...   \n",
       "3      Sabag   ...     Tauchrohr TECEdrainline zu Ablauf superflach 1...   \n",
       "4      Sabag   ...     Membran-Geruchsverschluss für Ablauf TECEdrain...   \n",
       "\n",
       "  Joined_on  Preisdifferenz Art_Nr_Hersteller_Firma Category_Level_1  \\\n",
       "0       UID            -2.5                              Ersatzteile   \n",
       "1       UID            -2.5                              Ersatzteile   \n",
       "2       UID            -2.5                              Ersatzteile   \n",
       "3       UID            -2.5                              Ersatzteile   \n",
       "4       UID            -3.5                              Ersatzteile   \n",
       "\n",
       "     Category_Level_2 Category_Level_3  Category_Level_4 Closest Distance  \n",
       "0  zu Duschenelemente    TECEdrainline     TECEdrainline                   \n",
       "1  zu Duschenelemente    TECEdrainline     TECEdrainline                   \n",
       "2  zu Duschenelemente    TECEdrainline     TECEdrainline                   \n",
       "3  zu Duschenelemente    TECEdrainline     TECEdrainline                   \n",
       "4  zu Duschenelemente    TECEdrainline     TECEdrainline                   \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvt.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
